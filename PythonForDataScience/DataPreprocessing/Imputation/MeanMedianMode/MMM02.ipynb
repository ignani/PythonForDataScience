{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [sklearn.impute.IterativeImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html)\n",
    "\n",
    "## Multivariate\n",
    "\n",
    "Datasets contain missing values, often encoded as blanks, NaNs or other placeholders.\n",
    "Such datasets however are incompatible with scikit-learn estimators which assume that all values in an array are numerical,\n",
    "and that all have and hold meaning.\n",
    "\n",
    "Scikit learn library provides option to impute values various algorithms.\n",
    "- **Univariate imputation**<br>\n",
    "    which imputes values in the i-th feature dimension using only non-missing values in that feature dimension (e.g. impute.SimpleImputer).\n",
    "- **Multivariate imputation**<br>\n",
    "    use the entire set of available feature dimensions to estimate the missing values (e.g. impute.IterativeImputer).\n",
    "\n",
    "This sample covers imputing the missing values using **Multivariate** imputation.\n",
    "\n",
    "Compared to SimpleImputer, a more sophisticated approach is to use the **IterativeImputer** class, which models each feature with missing values as a function of other features, and uses that estimate for imputation.<br>\n",
    "It does so in an iterated round-robin fashion: \n",
    "- at each step, a feature column is designated as output y and the other feature columns are treated as inputs X. \n",
    "- A regressor is fit on (X, y) for known y. Then, the regressor is used to predict the missing values of y. \n",
    "- This is done for each feature in an iterative fashion, and then is repeated for max_iter imputation rounds. \n",
    "- The results of the final imputation round are returned.\n",
    "\n",
    "*class sklearn.impute.**IterativeImputer**(`estimator=None, missing_values=nan, sample_posterior=False, max_iter=10, tol=0.001, n_nearest_features=None, initial_strategy=’mean’, imputation_order=’ascending’, min_value=None, max_value=None, verbose=0, random_state=None, add_indicator=False`)*\n",
    "\n",
    "##### Parameters:\t\n",
    "- **estimator** : *estimator object, default=BayesianRidge().*<br>\n",
    "The estimator to use at each step of the round-robin imputation. If `sample_posterior` is True, the estimator must support `return_std` in its `predict` method.\n",
    "\n",
    "- **missing_values** : *int, np.nan, optional (default=np.nan).*<br>\n",
    "The placeholder for the missing values. All occurrences of `missing_values` will be imputed.\n",
    "\n",
    "- **sample_posterior** : *boolean, default=False.*<br>\n",
    "Whether to sample from the (Gaussian) predictive posterior of the fitted estimator for each imputation. Estimator must support `return_std` in its `predict` method if set to `True`. Set to `True` if using `IterativeImputer` for multiple imputations.\n",
    "\n",
    "- **max_iter** : *int, optional (default=10).*<br>\n",
    "Maximum number of imputation rounds to perform before returning the imputations computed during the final round. A round is a single imputation of each feature with missing values. The stopping criterion is met once `abs(max(X_t - X_{t-1}))/abs(max(X[known_vals])) < tol`, where `X_t` is `X` at iteration `t`.<br>Note that early stopping is only applied if `sample_posterior=False`.\n",
    "\n",
    "- **tol** : *float, optional (default=1e-3).*<br>\n",
    "Tolerance of the stopping condition.\n",
    "\n",
    "- **n_nearest_features** : *int, optional (default=None).*<br>\n",
    "Number of other features to use to estimate the missing values of each feature column. Nearness between features is measured using the absolute correlation coefficient between each feature pair (after initial imputation). To ensure coverage of features throughout the imputation process, the neighbor features are not necessarily nearest, but are drawn with probability proportional to correlation for each imputed target feature. Can provide significant speed-up when the number of features is huge. If None, all features will be used.\n",
    "\n",
    "- **initial_strategy** : *str, optional (default=”mean”).*<br>\n",
    "Which strategy to use to initialize the missing values. Same as the strategy parameter in sklearn.impute.SimpleImputer Valid values: {“mean”, “median”, “most_frequent”, or “constant”}.\n",
    "\n",
    "- **imputation_order** : *str, optional (default=”ascending”).*<br>\n",
    "The order in which the features will be imputed. Possible values:\n",
    "\n",
    "“ascending”\n",
    "From features with fewest missing values to most.\n",
    "\n",
    "“descending”\n",
    "From features with most missing values to fewest.\n",
    "\n",
    "“roman”\n",
    "Left to right.\n",
    "\n",
    "“arabic”\n",
    "Right to left.\n",
    "\n",
    "“random”\n",
    "A random order for each round.\n",
    "\n",
    "- **min_value** : *float, optional (default=None).*<br>\n",
    "Minimum possible imputed value. Default of None will set minimum to negative infinity.\n",
    "\n",
    "- **max_value** : *float, optional (default=None).*<br>\n",
    "Maximum possible imputed value. Default of None will set maximum to positive infinity.\n",
    "\n",
    "- **verbose** : *int, optional (default=0).*<br>\n",
    "Verbosity flag, controls the debug messages that are issued as functions are evaluated. The higher, the more verbose. Can be 0, 1, or 2.\n",
    "\n",
    "- **random_state** : *int, RandomState instance or None, optional (default=None).*<br>\n",
    "The seed of the pseudo random number generator to use. Randomizes selection of estimator features if n_nearest_features is not None, the imputation_order if random, and the sampling from posterior if sample_posterior is True. Use an integer for determinism. See the Glossary.\n",
    "\n",
    "- **add_indicator** : *boolean, optional (default=False).*<br>\n",
    "If True, a [MissingIndicator](http://localhost:8888/notebooks/PythonForDataScience/PythonForDataScience/DataPreprocessing/Imputation/MeanMedianMode/MMM03.ipynb) transform will stack onto output of the imputer’s transform. This allows a predictive estimator to account for missingness despite imputation. If a feature has no missing values at fit/train time, the feature won’t appear on the missing indicator even if there are missing values at transform/test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterativeImputer(add_indicator=False, estimator=None,\n",
       "                 imputation_order='ascending', initial_strategy='mean',\n",
       "                 max_iter=10, max_value=None, min_value=None,\n",
       "                 missing_values=nan, n_nearest_features=None, random_state=0,\n",
       "                 sample_posterior=False, tol=0.001, verbose=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp.fit([[1, 2], [3, 6], [4, 8], [np.nan, 3], [7, np.nan]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.],\n",
       "       [ 6., 12.],\n",
       "       [ 3.,  6.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [[np.nan, 2], [6, np.nan], [np.nan, 6]]\n",
    "# the model learns that the second feature is double the first\n",
    "np.round(imp.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
